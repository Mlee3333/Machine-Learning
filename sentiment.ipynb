{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text    label\n",
      "0                            i didnt feel humiliated  sadness\n",
      "1  i can go from feeling so hopeless to so damned...  sadness\n",
      "2   im grabbing a minute to post i feel greedy wrong    anger\n",
      "3  i am ever feeling nostalgic about the fireplac...     love\n",
      "4                               i am feeling grouchy    anger\n",
      "1    1704\n",
      "0    1496\n",
      "Name: label, dtype: int64\n",
      "1    7058\n",
      "0    5742\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sentimentdf = pd.read_csv(\"sentiments.txt\",sep=\";\",names=[\"text\",\"label\"])\n",
    "print(sentimentdf.head(5))\n",
    "sentimentdf[\"label\"]=sentimentdf[\"label\"].replace({\"sadness\":1,\"anger\":1,\"fear\":1,\"joy\":0,\"love\":0,\"surprise\":0})\n",
    "\n",
    "X = sentimentdf[\"text\"]\n",
    "y = sentimentdf[\"label\"]\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "\n",
    "print(ytest.value_counts())\n",
    "print(ytrain.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\morga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\morga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\morga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wne = WordNetLemmatizer()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feel like innocent victim feel win', 'im feeling little dazed confused today', 'feel acclimated like finally part organization rather timid observer', 'feel totally drained emotionally physically holy spirit never cease fill speak', 'find feeling surprised totally unworthy whenever see face']\n"
     ]
    }
   ],
   "source": [
    "def transform(data):\n",
    "    corpus = []\n",
    "    for i in data:\n",
    "        newi = re.sub(\"[^a-zA-Z]\",\" \",i)\n",
    "        newi = newi.lower()\n",
    "        newi = newi.split()\n",
    "        list1 = [wne.lemmatize(word)for word in newi if word not in stopwords.words(\"english\")]\n",
    "        corpus.append(\" \".join(list1))\n",
    "    return corpus\n",
    "\n",
    "Xtraincorpus = transform(Xtrain)\n",
    "\n",
    "print(Xtraincorpus[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12800, 88128)\n",
      "(3200, 88128)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "Xtrainnew = cv.fit_transform(Xtraincorpus)\n",
    "print(Xtrainnew.shape)\n",
    "Xtestcorpus = transform(Xtest)\n",
    "Xtestnew = cv.transform(Xtestcorpus)\n",
    "print(Xtestnew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5742\n",
      "           1       1.00      1.00      1.00      7058\n",
      "\n",
      "    accuracy                           1.00     12800\n",
      "   macro avg       1.00      1.00      1.00     12800\n",
      "weighted avg       1.00      1.00      1.00     12800\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      1496\n",
      "           1       0.95      0.96      0.95      1704\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.95      0.95      0.95      3200\n",
      "weighted avg       0.95      0.95      0.95      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(Xtrainnew,ytrain)\n",
    "trainpred = rfc.predict(Xtrainnew)\n",
    "\n",
    "print(classification_report(ytrain,trainpred))\n",
    "\n",
    "testpred = rfc.predict(Xtestnew)\n",
    "\n",
    "print(classification_report(ytest,testpred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'min_samples_leaf': 2, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"n_estimators\":[100,500,1000],\"max_depth\":[5,10,None],\"min_samples_leaf\":[1,2,5]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gscv = GridSearchCV(RandomForestClassifier(),parameters,n_jobs=-1)\n",
    "gscv.fit(Xtrainnew,ytrain)\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      5742\n",
      "           1       0.97      0.98      0.98      7058\n",
      "\n",
      "    accuracy                           0.97     12800\n",
      "   macro avg       0.98      0.97      0.97     12800\n",
      "weighted avg       0.97      0.97      0.97     12800\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1496\n",
      "           1       0.94      0.97      0.96      1704\n",
      "\n",
      "    accuracy                           0.95      3200\n",
      "   macro avg       0.96      0.95      0.95      3200\n",
      "weighted avg       0.95      0.95      0.95      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=gscv.best_params_[\"n_estimators\"],max_depth=gscv.best_params_[\"max_depth\"],min_samples_leaf=gscv.best_params_[\"min_samples_leaf\"])\n",
    "rfc.fit(Xtrainnew,ytrain)\n",
    "testpred = rfc.predict(Xtestnew)\n",
    "trainpred = rfc.predict(Xtrainnew)\n",
    "\n",
    "print(classification_report(ytrain,trainpred))\n",
    "print(classification_report(ytest,testpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "def newSentiment(text):\n",
    "    trtext = transform(text)\n",
    "    trtext = cv.transform(trtext)\n",
    "    textpred = rfc.predict(trtext)\n",
    "    if textpred[0] == 1:\n",
    "        print(\"negative\")\n",
    "    else:\n",
    "        print(\"positive\")\n",
    "\n",
    "str1 = [\"it is raining outside and i am unhappy\"]\n",
    "str2 = [\"the weather is good and i am excited\"]\n",
    "\n",
    "newSentiment(str1)\n",
    "newSentiment(str2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
